{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfa8bfd6-2c3f-488b-b5db-9f5b6782851e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac737d39-deef-4576-99e4-339a5508732f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f7eb43a-6638-4050-98df-c3bee164c7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|████████████████████| 76/76 [00:00<00:00, 582.28it/s, Materializing param=transformer.wte.weight]\n",
      "GPT2LMHeadModel LOAD REPORT from: distilgpt2\n",
      "Key                                        | Status     |  | \n",
      "-------------------------------------------+------------+--+-\n",
      "transformer.h.{0, 1, 2, 3, 4, 5}.attn.bias | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    }
   ],
   "source": [
    "ai_model = pipeline(\"text-generation\",model=\"distilgpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92185b96-96b5-4bff-b6c6-3ed23ef173fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "faq = {\n",
    "    \"price\": \"Our sarees start from ₹399.\",\n",
    "    \"cod\": \"Cash on Delivery is not available.\",\n",
    "    \"shipping\": \"Shipping charges depend on location.\",\n",
    "    \"saree\": \"We have Cotton and Semi Silk sarees.\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a9e5962-ceaf-4c75-b0d4-0db317286264",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_faq(question):\n",
    "    question = question.lower()\n",
    "    for key in faq:\n",
    "        if key in question:\n",
    "            return faq[key]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7007ac2e-18ef-48cf-af7e-6f87c8f2318f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Customer Support Chatbot\n",
      "Type 'exit' to stop\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  what is the price\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Our sarees start from ₹399.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  do you have cod?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Cash on Delivery is not available.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  what kind of sarees you have?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: We have Cotton and Semi Silk sarees.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  if have any shipping chrges?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Shipping charges depend on location.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  ok thank you\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing `generation_config` together with generation-related arguments=({'max_length', 'num_return_sequences'}) is deprecated and will be removed in future versions. Please pass either a `generation_config` object OR all generation parameters explicitly, but not both.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: ok thank you for your time, and we will be doing our best to help you.\n",
      "\n",
      "\n",
      "\n",
      "We wish you all the best in your endeavors.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Thank you\n"
     ]
    }
   ],
   "source": [
    "print(\"AI Customer Support Chatbot\")\n",
    "print(\"Type 'exit' to stop\")\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "\n",
    "    if user_input.lower() == \"exit\":\n",
    "        print(\"Bot: Thank you\")\n",
    "        break\n",
    "\n",
    "    faq_answer = check_faq(user_input)\n",
    "\n",
    "    if faq_answer:\n",
    "        print(\"Bot:\", faq_answer)\n",
    "    else:\n",
    "        response = ai_model(\n",
    "            user_input,\n",
    "            max_length=60,\n",
    "            num_return_sequences=1\n",
    "        )\n",
    "        print(\"Bot:\", response[0][\"generated_text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3444e8a6-79f0-48a2-b413-0ef7983e09f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
